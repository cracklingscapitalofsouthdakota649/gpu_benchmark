# ğŸ¤– GPU/CPU Benchmark Suite

A robust benchmarking framework for evaluating GPU and CPU performance using PyTorch, pytest, and Allure reporting.  
Supports NVIDIA, AMD, Intel, DirectML, and CPU-only execution, with performance metrics and interactive dashboards.

---

## ğŸ‘¤ Author & Contact  
**Author:** Bang Thien Nguyen  
**Contact:** ontario1998@gmail.com  

---

## ğŸ’¡ Project Overview  
This framework implements **GPU/CPU performance benchmarking** using `pytest` and `pytest-benchmark`.  
It automatically detects available accelerators, measures inference throughput, GPU/CPU utilization, and memory usage, and produces **interactive Allure reports** for analysis.

| **Component** | **Technology** | **Role** |
|---------------|----------------|----------|
| Test Runner | **pytest** | Executes benchmark and stress tests. |
| Performance Metrics | **pytest-benchmark / SystemMetrics** | Measures FPS, CPU/GPU utilization, memory usage. |
| GPU Detection | **gpu_check.py** | Detects NVIDIA CUDA, AMD ROCm, Intel GPU, DirectML, or CPU fallback. |
| Reporting | **Allure** | Generates professional, interactive HTML dashboards with charts. |

---

## ğŸš€ Getting Started  

### ğŸ”§ Prerequisites  
- ğŸ Python 3.10+ (recommended)  
- ğŸ“ˆ Optional: Allure command-line tool for report viewing  
- ğŸ’» Windows or Linux system with GPU support (optional for CPU-only fallback)  

### âš™ï¸ Installation  

Clone the repository:  
```bash
git clone https://github.com/luckyjoy/gpu_benchmark.git
cd gpu_benchmark
```

Run the setup script to create a virtual environment, install dependencies, and detect GPU:  
```bash
python gpu_benchmark.py
```

The script will:  
- Create `venv310` if missing  
- Detect available GPU or fall back to CPU  
- Install all required packages including PyTorch  
- Run benchmark tests and store results in `allure-results/`  

---

## ğŸ³ Dockerized Execution (Optional)

Ensure consistent results across systems by running inside Docker.

### ğŸ§± Docker Image  
Image: **`gpu-benchmark:latest`** â€” includes:  
- Python 3.10 environment  
- PyTorch & required packages preinstalled  
- Allure CLI for reporting  
- `/app` as working directory  

### â–¶ï¸ Run Tests via Script  

**Script:** `run_docker.bat` (Windows)  
**Workflow:**  

| **Step** | **Description** |
|-----------|-----------------|
| 1ï¸âƒ£ Check Docker | Verifies Docker Desktop is running. |
| 2ï¸âƒ£ Clean Up | Deletes previous `allure-results` and `.benchmarks`. |
| 3ï¸âƒ£ Build / Pull | Builds or updates Docker image. |
| 4ï¸âƒ£ Execute Tests | Runs GPU/CPU benchmark suite. |
| 5ï¸âƒ£ Generate Report | Produces Allure HTML output. |
| 6ï¸âƒ£ Serve Report | Opens Allure dashboard locally. |

Command to execute:  
```bash
run_docker.bat
```

---

## ğŸŒ³ Framework Architecture  

```
gpu_benchmark/
â”œâ”€ README.md
â”œâ”€ gpu_benchmark.py           # Setup & execution script
â”œâ”€ pytest.ini                 # Pytest configuration
â”œâ”€ supports/                  # GPU detection & utility scripts
â”‚  â””â”€ gpu_check.py
â”œâ”€ scripts/
â”‚  â”œâ”€ plot_gpu_metrics.py     # Generate charts for Allure
â”‚  â””â”€ system_metrics.py       # Capture CPU/GPU metrics
â”œâ”€ tests/                     # Benchmark test cases
â”‚  â”œâ”€ test_data_preprocessing.py
â”‚  â”œâ”€ test_gpu_stress.py
â”‚  â”œâ”€ test_inference_load.py
â”‚  â””â”€ test_idle_baseline.py
â”œâ”€ venv310/                   # Virtual environment (auto-created)
â”œâ”€ allure-results/            # Benchmark reports
â””â”€ .benchmarks/               # Pytest-benchmark history
```

---

## ğŸ·ï¸ Test Tags & Execution  

| **Tag** | **Focus Area** | **Description** |
|----------|----------------|-----------------|
| `gpu` | GPU Benchmark | Tests running on CUDA/ROCm/DirectML/Intel GPU. |
| `cpu` | CPU Benchmark | Tests running on CPU fallback. |
| `stress` | GPU Stress | Heavy-load GPU endurance tests. |
| `benchmark` | Performance | FPS, utilization, memory measurement. |

### ğŸ§ª Run CMD Tests Locally  

| **Mode** | **Command** |
|-----------|-------------|
| Run All GPU Tests | `pytest -m gpu --alluredir=allure-results -v` |
| Run All CPU Tests | `pytest -m cpu --alluredir=allure-results -v` |
| Run Specific Benchmark | `pytest -m "benchmark and gpu"` |

---

## ğŸ“Š Professional Test Reporting  

### 1ï¸âƒ£ **Interactive Allure Report (Recommended)**  
```bash
pytest -m gpu --alluredir=allure-results
allure serve allure-results
```

ğŸ“¸ *Preview of GPU Metrics Dashboard:*  

![Allure Overview Report](docs/screenshots/allure_gpu_overview.png)  
*Shows FPS, GPU utilization, and memory usage over time.*

![Allure Pytest Suites Report](docs/screenshots/allure_gpu_suites.png)  
*Detailed view per test with step-by-step metrics.*

ğŸ“¸ *CPU Metrics Preview:*  

![Allure CPU Overview](docs/screenshots/allure_cpu_overview.png)  
*Tracks CPU utilization, memory usage, and benchmark throughput.*

> Opens an interactive HTML dashboard with detailed execution insights.

### 2ï¸âƒ£ **Static HTML Report (Optional)**  
```bash
pytest --html=reports/report.html --self-contained-html
```

---

## âš™ï¸ CI/CD Integration

| System | Description |
|--------|-------------|
| Jenkins / GitHub Actions | Automates test execution and report generation |
| Docker | Guarantees repeatable benchmark environments |
| Allure | Produces professional dashboards for CI/CD pipelines |

---

## ğŸ¤ Contributing Guidelines

1. Fork the repository  
2. Create a feature branch  
3. Implement new tests, benchmarks, or reporting features  
4. Run `pytest -v` locally and verify results  
5. Submit a Pull Request with a clear description  

**Code Style:**  
- Follow **PEP8** conventions  
- Use **pytest markers** consistently  
- Ensure **Allure reports** generate without errors  
- Document new metrics or tests in **Allure charts**  

---

## ğŸªª License

Released under the **MIT License** â€” free to use, modify, and distribute.

---

ğŸ“¬ *Contact:* [ontario1998@gmail.com](mailto:ontario1998@gmail.com)  

> _â€œMeasure performance before you optimize â€” know your hardware before you test your code.â€_
